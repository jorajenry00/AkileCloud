# Windsurf Cascade 如何通过 AI 提升工作效率？

从今天开始，将 AI 视为你的合作伙伴，一起创造无限可能！

![Windsurf AI 示意图](https://bbtdd.com/img/768940291876.webp)

## 新工具介绍

Windsurf 已经发布一段时间了。最近，官方推出了黑五优惠活动，并在知识星球中进行了通知。

![黑五优惠](https://bbtdd.com/img/36786789.webp)

然而，由于优惠活动过于火爆，官方宣布将试用期延长至 12 月 11 日。

![试用期延长](https://bbtdd.com/img/7243756531.webp)

相较于原本的两个月试用期，这次延长后的时间显然缩短了不少。在 11 日之后，我们是否还能继续使用 pro 账号，暂时还是一个未知数。

许多用户对 Windsurf 表示出极大的兴趣，并在知识星球上分享了他们的使用心得。例如，有星友开发了 Todoist 和 Obsidian 的链接插件。

![Todoist 和 Obsidian 插件](https://bbtdd.com/img/881613009174992.webp)

还有星友更进一步，开发了智能 PDF 翻译应用。

![智能 PDF 翻译应用](https://bbtdd.com/img/81778670380.webp)

看到大家如此热情，你是否也迫不及待地想尝试 Windsurf 了呢？然而，许多用户尚未完全掌握 Windsurf，尤其是其特色的 Windsurf Cascade 功能。

如果你查阅相关介绍，会了解到一些定义：

- **Cascade** 是一个强大的推理引擎，能够进行深度的多步骤思考，具备编辑和解释代码的能力。
- **Cascade** 具备实时感知开发者行为的能力，能够基于持续的工作内容执行、调整和继续编辑任务。

那么，这些定义具体意味着什么呢？接下来，我们将通过一个实际例子，展示 Windsurf Cascade 的强大功能，帮助你快速开发原型系统，满足实际需求。

👉 [WildCard | 一分钟注册，轻松订阅海外线上服务](https://bbtdd.com/WildCard)

## 实际应用案例

这个案例将从网上一个现有的 API 作为起点，根据我们的需求进行调整，生成一个自定义软件包，并使其可供全球下载安装。此外，我们还会在本地搭建一个 Web 界面，方便用户使用。

听起来是否复杂？其实非常简单。

首先，我们来看一看这个 API。

![API 示意图](https://bbtdd.com/img/0255592323817.webp)

这个 API 由 Jina AI 提供，主要用于长文本的分片处理。

你或许还记得，在我之前开发的 [Python AI 工作流框架](https://blog.csdn.net/nkwshuyi/article/details/144255037) 中，长文本分片是一个重要功能。由于大语言模型存在上下文限制，超出窗口范围的内容将无法处理。在 Openrouter 的模型列表左侧，你可以清晰看到 Context Length 这一项，其范围从 4K 到 1M 不等。

![Context Length](https://bbtdd.com/img/13610427174968.webp)

此外，即使模型支持较长的上下文窗口，如果不限制分片长度，模型输出时可能会自动“精简”输出长度，这在长文写作和翻译中尤为不利，因为许多细节会被忽略。

在之前的 Python 框架中，我使用了 Langchain 的 RecursiveCharacterTextSplitter 进行操作。

![Langchain 分片工具](https://bbtdd.com/img/2610159166635134.webp)

当然，这个解释也是 Windsurf 分析代码库后自动生成的。

![Windsurf 分析结果](https://bbtdd.com/img/35098536707645.webp)

然而，我对 Langchain 的分片方式并不满意。边缘处出现的 overlap 总会带来意想不到的问题，例如标题或标题后的一句话重复出现。如果不进行人工检查，这些问题很容易出现在最终结果中。

那么，如果将 overlap 设置为 0，让两个分片之间没有任何重叠，是否就能解决问题？

每当一个问题显而易见时，我们应多思考一步——这是否是开发者的“解决方案”呢？如果设置 overlap 为 0，在标点符号缺失的情况下，一句话可能会被截断，导致问题更加严重。

既然原有的分片方式存在问题，当我看到 Jina AI 提供的 segmenter API 时，决定尝试一下。

在官网上测试中英文长文的分片效果后，我发现其实效果不错。

![中英文分片效果](https://bbtdd.com/img/823670494659.webp)

其中，中文测试使用了古文。

![古文中分片效果](https://bbtdd.com/img/8009346305.webp)

然而，你可能会发现——这个工具的分段虽然好，但过于稀疏了。我们原本希望每段不超过一定的 token 数量（例如这里设定的是 1000），但分拆的结果居然是一行一段，甚至一句一段，很多段的字符数仅有个位数。

这就有些“过犹不及”了——将一篇文章拆成 3-4 部分交给工作流，与拆成 30-40 部分相比，运行效率显然相差甚远。毕竟每次调用模型都会因提示词和上下文增加额外开销，不仅处理速度变慢，还会导致更高的费用。

那么，该如何解决呢？我决定让 Windsurf Cascade 来接手。